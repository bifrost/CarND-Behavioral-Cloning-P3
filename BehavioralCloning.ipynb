{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/center_2018_08...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/right_2018_08_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/center_2018_08...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/right_2018_08_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/center_2018_08...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/right_2018_08_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/center_2018_08...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/right_2018_08_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/center_2018_08...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...</td>\n",
       "      <td>/Users/dan/Desktop/car-sim1/IMG/right_2018_08_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  /Users/dan/Desktop/car-sim1/IMG/center_2018_08...   \n",
       "1  /Users/dan/Desktop/car-sim1/IMG/center_2018_08...   \n",
       "2  /Users/dan/Desktop/car-sim1/IMG/center_2018_08...   \n",
       "3  /Users/dan/Desktop/car-sim1/IMG/center_2018_08...   \n",
       "4  /Users/dan/Desktop/car-sim1/IMG/center_2018_08...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  /Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...   \n",
       "1  /Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...   \n",
       "2  /Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...   \n",
       "3  /Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...   \n",
       "4  /Users/dan/Desktop/car-sim1/IMG/left_2018_08_2...   \n",
       "\n",
       "                                                   2    3    4  5         6  \n",
       "0  /Users/dan/Desktop/car-sim1/IMG/right_2018_08_...  0.0  0.0  0  0.000006  \n",
       "1  /Users/dan/Desktop/car-sim1/IMG/right_2018_08_...  0.0  0.0  0  0.000012  \n",
       "2  /Users/dan/Desktop/car-sim1/IMG/right_2018_08_...  0.0  0.0  0  0.000006  \n",
       "3  /Users/dan/Desktop/car-sim1/IMG/right_2018_08_...  0.0  0.0  0  0.000004  \n",
       "4  /Users/dan/Desktop/car-sim1/IMG/right_2018_08_...  0.0  0.0  0  0.000010  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './data/car-sim1/'\n",
    "img_path = './data/car-sim1/IMG/'\n",
    "df = pd.read_csv(data_path+'driving_log.csv', header=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "lines = []\n",
    "with open(data_path+'driving_log.csv') as csvFile:\n",
    "    reader = csv.reader(csvFile)\n",
    "    #next(reader, None)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "def process_image(img): \n",
    "    # preprocess input\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (6861, 160, 320, 3)\n",
      "Y_train: (6861,)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    '''\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = img_path + filename\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "    '''\n",
    "    \n",
    "    steering_center = float(line[3])\n",
    "\n",
    "    # create adjusted steering measurements for the side camera images\n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    steering_right = steering_center - correction\n",
    "\n",
    "    # read in images from center, left and right cameras\n",
    "    filename = line[0].split('/')[-1]\n",
    "    img_center = process_image(cv2.imread(img_path + filename))\n",
    "    filename = line[1].split('/')[-1]\n",
    "    img_left = process_image(cv2.imread(img_path + filename))\n",
    "    filename = line[2].split('/')[-1]\n",
    "    img_right = process_image(cv2.imread(img_path + filename))\n",
    "\n",
    "    # add images and angles to data set\n",
    "    images.extend([img_center, img_left, img_right])\n",
    "    measurements.extend([steering_center, steering_left, steering_right])\n",
    "    \n",
    "X_train = np.array(images)\n",
    "Y_train = np.array(measurements)\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('Y_train:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: (2287, 160, 320, 3)\n",
      "measurements: (2287,)\n"
     ]
    }
   ],
   "source": [
    "images_center = []\n",
    "images_left = []\n",
    "images_right = []\n",
    "measurements_center = []\n",
    "measurements_left = []\n",
    "measurements_right = []\n",
    "for line in lines:\n",
    "\n",
    "    steering_center = float(line[3])\n",
    "\n",
    "    # create adjusted steering measurements for the side camera images\n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    steering_right = steering_center - correction\n",
    "\n",
    "    # read in images from center, left and right cameras\n",
    "    filename = line[0].split('/')[-1]\n",
    "    img_center = process_image(cv2.imread(img_path + filename))\n",
    "    \n",
    "    filename = line[1].split('/')[-1]\n",
    "    img_left = process_image(cv2.imread(img_path + filename))\n",
    "    \n",
    "    filename = line[2].split('/')[-1]\n",
    "    img_right = process_image(cv2.imread(img_path + filename))\n",
    "    \n",
    "    # add images and angles to data set\n",
    "    images_center.append(img_center)\n",
    "    images_left.append(img_left)\n",
    "    images_right.append(img_right)\n",
    "    \n",
    "    measurements_center.append(steering_center)\n",
    "    measurements_left.append(steering_left)\n",
    "    measurements_right.append(steering_right)\n",
    "    \n",
    "# convert to array\n",
    "images_center = np.array(images_center)\n",
    "images_left = np.array(images_left)\n",
    "images_right = np.array(images_right)\n",
    "\n",
    "measurements_center = np.array(measurements_center)\n",
    "measurements_left = np.array(measurements_left)\n",
    "measurements_right = np.array(measurements_right)\n",
    "    \n",
    "print('images:', images_center.shape)\n",
    "print('measurements:', measurements_center.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_idx: 1600\n",
      "val_idx: 343\n",
      "test_idx: 344\n",
      "images_train: (9600, 160, 320, 3)\n",
      "measurements_train: (9600,)\n",
      "images_val: (343, 160, 320, 3)\n",
      "measurements_val: (343,)\n",
      "images_test: (344, 160, 320, 3)\n",
      "measurements_test: (344,)\n"
     ]
    }
   ],
   "source": [
    "# split 70/15/15\n",
    "length = len(measurements_center)\n",
    "train_size = int(length * 0.7)\n",
    "\n",
    "indices = np.random.permutation(length)\n",
    "train_idx, test_idx = indices[:train_size], indices[train_size:]\n",
    "\n",
    "val_size = int(len(test_idx) * 0.5)\n",
    "val_idx, test_idx = test_idx[:val_size], test_idx[val_size:]\n",
    "\n",
    "print('train_idx:', len(train_idx))\n",
    "print('val_idx:', len(val_idx))\n",
    "print('test_idx:', len(test_idx))\n",
    "\n",
    "images_train = np.concatenate((\n",
    "    images_center[train_idx], \n",
    "    images_left[train_idx], \n",
    "    images_right[train_idx]\n",
    "))\n",
    "measurements_train = np.concatenate((\n",
    "    measurements_center[train_idx], \n",
    "    measurements_left[train_idx], \n",
    "    measurements_right[train_idx]\n",
    "))\n",
    "\n",
    "images_val, measurements_val = images_center[val_idx], measurements_center[val_idx]\n",
    "images_test, measurements_test = images_center[test_idx], measurements_center[test_idx]\n",
    "\n",
    "# augmented train set\n",
    "augmented_images = []\n",
    "augmented_measurements = []\n",
    "for image, measurement in zip(images_train, measurements_train):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image,1))\n",
    "    augmented_measurements.append(measurement*-1.0)\n",
    "    \n",
    "images_train = np.array(augmented_images)\n",
    "measurements_train = np.array(augmented_measurements)\n",
    "    \n",
    "    \n",
    "print('images_train:', images_train.shape)\n",
    "print('measurements_train:', measurements_train.shape)\n",
    "print('images_val:', images_val.shape)\n",
    "print('measurements_val:', measurements_val.shape)\n",
    "print('images_test:', images_test.shape)\n",
    "print('measurements_test:', measurements_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (9600, 160, 320, 3)\n",
      "Y_train: (9600,)\n"
     ]
    }
   ],
   "source": [
    "X_train = images_train\n",
    "Y_train = measurements_train\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('Y_train:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10972 samples, validate on 2744 samples\n",
      "Epoch 1/2\n",
      "10972/10972 [==============================] - 7s 677us/step - loss: 0.0980 - val_loss: 0.1220\n",
      "Epoch 2/2\n",
      "10972/10972 [==============================] - 7s 623us/step - loss: 0.0578 - val_loss: 0.1509\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Flatten(input_shape=(160, 320, 3)))\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.0001))\n",
    "model.fit(X_train, Y_train, validation_split=0.2, shuffle=True, epochs=2)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10977 samples, validate on 2745 samples\n",
      "Epoch 1/3\n",
      "10977/10977 [==============================] - 10s 889us/step - loss: 0.5664 - val_loss: 0.0745\n",
      "Epoch 2/3\n",
      "10977/10977 [==============================] - 9s 796us/step - loss: 0.0437 - val_loss: 0.0645\n",
      "Epoch 3/3\n",
      "10977/10977 [==============================] - 9s 803us/step - loss: 0.0374 - val_loss: 0.0639\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5))\n",
    "model.add(Conv2D(6, (5,5), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(6, (5,5), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "model.fit(X_train, Y_train, validation_split=0.2, shuffle=True, epochs=3)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dra/anaconda3/envs/tensorflow3.6/lib/python3.6/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 6 0           activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, None, None, 2 0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, None, None, 2 0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, None, None, 2 0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, None, None, 5 0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, None, None, 5 0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, None, None, 5 0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, None, None, 5 0           add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, None, None, 1 0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, None, None, 1 0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, None, None, 1 0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, None, None, 1 0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, None, None, 1 0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, None, None, 1 0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, None, None, 2 0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, None, None, 2 0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, None, None, 2 0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 2048)         0           activation_245[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "modelTransfer = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "x = modelTransfer.output\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "net = Model(inputs=modelTransfer.input, outputs=x)\n",
    "net.summary()\n",
    "\n",
    "def get_bottleneck_feature(img):\n",
    "    # convert 3D tensor to 4D tensor with shape (1, ?, ?, 3) and return 4D tensor\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # preprocess input\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    return net.predict(x)\n",
    "\n",
    "def get_bottleneck_features(images):\n",
    "    bottleneck_features = []\n",
    "\n",
    "    for img in tqdm(images):\n",
    "        bottleneck_features.append(get_bottleneck_feature(img))\n",
    "        #try:\n",
    "        #    bottleneck_features.append(bottleneck_feature(img))\n",
    "        #except OSError:\n",
    "        #    None \n",
    "            \n",
    "    return np.vstack(bottleneck_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 9600/9600 [01:51<00:00, 85.74it/s]\n",
      "100%|| 343/343 [00:03<00:00, 89.40it/s]\n",
      "100%|| 344/344 [00:03<00:00, 86.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (9600, 2048)\n",
      "X_val: (343, 2048)\n",
      "X_test: (344, 2048)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "X_train = get_bottleneck_features(images_train)\n",
    "Y_train = measurements_train\n",
    "\n",
    "X_val = get_bottleneck_features(images_val)\n",
    "Y_val = measurements_val\n",
    "\n",
    "X_test = get_bottleneck_features(images_test)\n",
    "Y_test = measurements_test\n",
    "\n",
    "bottleneck_feature = {\n",
    "    'X_train': X_train,\n",
    "    'Y_train': Y_train,\n",
    "    'X_val': X_val,\n",
    "    'Y_val': Y_val,\n",
    "    'X_test': X_test,\n",
    "    'Y_test': Y_test\n",
    "}\n",
    "\n",
    "with open('models/bottleneck_feature.pickle', 'wb') as f:\n",
    "    pickle.dump(bottleneck_feature, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print('X_train:', X_train.shape)\n",
    "print('X_val:', X_val.shape)\n",
    "print('X_test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9600, 2048)\n",
      "(9600,)\n",
      "(343, 2048)\n",
      "(343,)\n",
      "(344, 2048)\n",
      "(344,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/bottleneck_feature.pickle', 'rb') as f:\n",
    "    bottleneck_feature = pickle.load(f)\n",
    "    \n",
    "X_train = bottleneck_feature['X_train']\n",
    "Y_train = bottleneck_feature['Y_train']\n",
    "\n",
    "X_val = bottleneck_feature['X_val']\n",
    "Y_val = bottleneck_feature['Y_val']\n",
    "\n",
    "X_test = bottleneck_feature['X_test']\n",
    "Y_test = bottleneck_feature['Y_test']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 590,593\n",
      "Trainable params: 590,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.02), input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.02)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9600 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "9600/9600 [==============================] - 1s 103us/step - loss: 15.0391 - val_loss: 12.9614\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 12.96139, saving model to models/weights.best.hdf5\n",
      "Epoch 2/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 12.1603 - val_loss: 11.4924\n",
      "\n",
      "Epoch 00002: val_loss improved from 12.96139 to 11.49240, saving model to models/weights.best.hdf5\n",
      "Epoch 3/100\n",
      "9600/9600 [==============================] - 1s 74us/step - loss: 10.8512 - val_loss: 10.3000\n",
      "\n",
      "Epoch 00003: val_loss improved from 11.49240 to 10.30002, saving model to models/weights.best.hdf5\n",
      "Epoch 4/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 9.8082 - val_loss: 9.3318\n",
      "\n",
      "Epoch 00004: val_loss improved from 10.30002 to 9.33177, saving model to models/weights.best.hdf5\n",
      "Epoch 5/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 8.9154 - val_loss: 8.4911\n",
      "\n",
      "Epoch 00005: val_loss improved from 9.33177 to 8.49115, saving model to models/weights.best.hdf5\n",
      "Epoch 6/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 8.1145 - val_loss: 7.7266\n",
      "\n",
      "Epoch 00006: val_loss improved from 8.49115 to 7.72657, saving model to models/weights.best.hdf5\n",
      "Epoch 7/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 7.3785 - val_loss: 7.0232\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.72657 to 7.02321, saving model to models/weights.best.hdf5\n",
      "Epoch 8/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 6.6994 - val_loss: 6.3776\n",
      "\n",
      "Epoch 00008: val_loss improved from 7.02321 to 6.37760, saving model to models/weights.best.hdf5\n",
      "Epoch 9/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 6.0675 - val_loss: 5.7571\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.37760 to 5.75709, saving model to models/weights.best.hdf5\n",
      "Epoch 10/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 5.4767 - val_loss: 5.1886\n",
      "\n",
      "Epoch 00010: val_loss improved from 5.75709 to 5.18860, saving model to models/weights.best.hdf5\n",
      "Epoch 11/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 4.9256 - val_loss: 4.6630\n",
      "\n",
      "Epoch 00011: val_loss improved from 5.18860 to 4.66302, saving model to models/weights.best.hdf5\n",
      "Epoch 12/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 4.4175 - val_loss: 4.1662\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.66302 to 4.16622, saving model to models/weights.best.hdf5\n",
      "Epoch 13/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 3.9399 - val_loss: 3.7168\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.16622 to 3.71685, saving model to models/weights.best.hdf5\n",
      "Epoch 14/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 3.5023 - val_loss: 3.3028\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.71685 to 3.30281, saving model to models/weights.best.hdf5\n",
      "Epoch 15/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 3.1019 - val_loss: 2.9326\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.30281 to 2.93256, saving model to models/weights.best.hdf5\n",
      "Epoch 16/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 2.7376 - val_loss: 2.5696\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.93256 to 2.56960, saving model to models/weights.best.hdf5\n",
      "Epoch 17/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 2.4066 - val_loss: 2.2492\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.56960 to 2.24921, saving model to models/weights.best.hdf5\n",
      "Epoch 18/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 2.1065 - val_loss: 1.9654\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.24921 to 1.96538, saving model to models/weights.best.hdf5\n",
      "Epoch 19/100\n",
      "9600/9600 [==============================] - 1s 74us/step - loss: 1.8395 - val_loss: 1.7132\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.96538 to 1.71318, saving model to models/weights.best.hdf5\n",
      "Epoch 20/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 1.5982 - val_loss: 1.4924\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.71318 to 1.49241, saving model to models/weights.best.hdf5\n",
      "Epoch 21/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 1.3883 - val_loss: 1.3037\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.49241 to 1.30366, saving model to models/weights.best.hdf5\n",
      "Epoch 22/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 1.2015 - val_loss: 1.1179\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.30366 to 1.11793, saving model to models/weights.best.hdf5\n",
      "Epoch 23/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 1.0395 - val_loss: 0.9726\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.11793 to 0.97256, saving model to models/weights.best.hdf5\n",
      "Epoch 24/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.8976 - val_loss: 0.8331\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.97256 to 0.83309, saving model to models/weights.best.hdf5\n",
      "Epoch 25/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.7760 - val_loss: 0.7174\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.83309 to 0.71742, saving model to models/weights.best.hdf5\n",
      "Epoch 26/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.6705 - val_loss: 0.6209\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.71742 to 0.62090, saving model to models/weights.best.hdf5\n",
      "Epoch 27/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.5813 - val_loss: 0.5403\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.62090 to 0.54030, saving model to models/weights.best.hdf5\n",
      "Epoch 28/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.5039 - val_loss: 0.4750\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.54030 to 0.47499, saving model to models/weights.best.hdf5\n",
      "Epoch 29/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.4400 - val_loss: 0.4094\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.47499 to 0.40943, saving model to models/weights.best.hdf5\n",
      "Epoch 30/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.3852 - val_loss: 0.3584\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.40943 to 0.35836, saving model to models/weights.best.hdf5\n",
      "Epoch 31/100\n",
      "9600/9600 [==============================] - 1s 77us/step - loss: 0.3421 - val_loss: 0.3182\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.35836 to 0.31824, saving model to models/weights.best.hdf5\n",
      "Epoch 32/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.3018 - val_loss: 0.2837\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.31824 to 0.28374, saving model to models/weights.best.hdf5\n",
      "Epoch 33/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.2680 - val_loss: 0.2538\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.28374 to 0.25378, saving model to models/weights.best.hdf5\n",
      "Epoch 34/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.2394 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.25378 to 0.22857, saving model to models/weights.best.hdf5\n",
      "Epoch 35/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.2159 - val_loss: 0.2087\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.22857 to 0.20870, saving model to models/weights.best.hdf5\n",
      "Epoch 36/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.1959 - val_loss: 0.1841\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.20870 to 0.18406, saving model to models/weights.best.hdf5\n",
      "Epoch 37/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 0.1761 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18406 to 0.16989, saving model to models/weights.best.hdf5\n",
      "Epoch 38/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.1605 - val_loss: 0.1524\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.16989 to 0.15244, saving model to models/weights.best.hdf5\n",
      "Epoch 39/100\n",
      "9600/9600 [==============================] - 1s 74us/step - loss: 0.1451 - val_loss: 0.1378\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15244 to 0.13781, saving model to models/weights.best.hdf5\n",
      "Epoch 40/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.1316 - val_loss: 0.1272\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.13781 to 0.12718, saving model to models/weights.best.hdf5\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 1s 73us/step - loss: 0.1195 - val_loss: 0.1149\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.12718 to 0.11486, saving model to models/weights.best.hdf5\n",
      "Epoch 42/100\n",
      "9600/9600 [==============================] - 1s 74us/step - loss: 0.1086 - val_loss: 0.1050\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.11486 to 0.10498, saving model to models/weights.best.hdf5\n",
      "Epoch 43/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.0981 - val_loss: 0.0958\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.10498 to 0.09576, saving model to models/weights.best.hdf5\n",
      "Epoch 44/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0889 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.09576 to 0.08989, saving model to models/weights.best.hdf5\n",
      "Epoch 45/100\n",
      "9600/9600 [==============================] - 1s 67us/step - loss: 0.0807 - val_loss: 0.0802\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.08989 to 0.08025, saving model to models/weights.best.hdf5\n",
      "Epoch 46/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0737 - val_loss: 0.0743\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08025 to 0.07431, saving model to models/weights.best.hdf5\n",
      "Epoch 47/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0671 - val_loss: 0.0671\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.07431 to 0.06712, saving model to models/weights.best.hdf5\n",
      "Epoch 48/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0613 - val_loss: 0.0622\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.06712 to 0.06222, saving model to models/weights.best.hdf5\n",
      "Epoch 49/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 0.0574 - val_loss: 0.0574\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.06222 to 0.05736, saving model to models/weights.best.hdf5\n",
      "Epoch 50/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.0524 - val_loss: 0.0550\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.05736 to 0.05498, saving model to models/weights.best.hdf5\n",
      "Epoch 51/100\n",
      "9600/9600 [==============================] - 1s 74us/step - loss: 0.0488 - val_loss: 0.0519\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.05498 to 0.05195, saving model to models/weights.best.hdf5\n",
      "Epoch 52/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.0462 - val_loss: 0.0476\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.05195 to 0.04762, saving model to models/weights.best.hdf5\n",
      "Epoch 53/100\n",
      "9600/9600 [==============================] - 1s 75us/step - loss: 0.0430 - val_loss: 0.0485\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04762\n",
      "Epoch 54/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0412 - val_loss: 0.0443\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.04762 to 0.04432, saving model to models/weights.best.hdf5\n",
      "Epoch 55/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.0403 - val_loss: 0.0447\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04432\n",
      "Epoch 56/100\n",
      "9600/9600 [==============================] - 1s 74us/step - loss: 0.0380 - val_loss: 0.0422\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04432 to 0.04216, saving model to models/weights.best.hdf5\n",
      "Epoch 57/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0367 - val_loss: 0.0426\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04216\n",
      "Epoch 58/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0360 - val_loss: 0.0413\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.04216 to 0.04127, saving model to models/weights.best.hdf5\n",
      "Epoch 59/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 0.0350 - val_loss: 0.0412\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.04127 to 0.04124, saving model to models/weights.best.hdf5\n",
      "Epoch 60/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.0347 - val_loss: 0.0406\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.04124 to 0.04059, saving model to models/weights.best.hdf5\n",
      "Epoch 61/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0343 - val_loss: 0.0395\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.04059 to 0.03953, saving model to models/weights.best.hdf5\n",
      "Epoch 62/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0332 - val_loss: 0.0420\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.03953\n",
      "Epoch 63/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 0.0337 - val_loss: 0.0415\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.03953\n",
      "Epoch 64/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.0320 - val_loss: 0.0454\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.03953\n",
      "Epoch 65/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0334 - val_loss: 0.0410\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.03953\n",
      "Epoch 66/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 0.0321 - val_loss: 0.0419\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.03953\n",
      "Epoch 67/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 0.0318 - val_loss: 0.0409\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.03953\n",
      "Epoch 68/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 0.0314 - val_loss: 0.0410\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.03953\n",
      "Epoch 69/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 0.0314 - val_loss: 0.0415\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.03953\n",
      "Epoch 70/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.0310 - val_loss: 0.0400\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03953\n",
      "Epoch 71/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 0.0308 - val_loss: 0.0453\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.03953\n",
      "Epoch 72/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 0.0312 - val_loss: 0.0419\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.03953\n",
      "Epoch 73/100\n",
      "9600/9600 [==============================] - 1s 77us/step - loss: 0.0318 - val_loss: 0.0423\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.03953\n",
      "Epoch 74/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0311 - val_loss: 0.0434\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03953\n",
      "Epoch 75/100\n",
      "9600/9600 [==============================] - 1s 67us/step - loss: 0.0310 - val_loss: 0.0445\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.03953\n",
      "Epoch 76/100\n",
      "9600/9600 [==============================] - 1s 68us/step - loss: 0.0309 - val_loss: 0.0406\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.03953\n",
      "Epoch 77/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.0307 - val_loss: 0.0430\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03953\n",
      "Epoch 78/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.0310 - val_loss: 0.0506\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.03953\n",
      "Epoch 79/100\n",
      "9600/9600 [==============================] - 1s 74us/step - loss: 0.0298 - val_loss: 0.0422\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.03953\n",
      "Epoch 80/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.0304 - val_loss: 0.0416\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.03953\n",
      "Epoch 81/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.0311 - val_loss: 0.0467\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.03953\n",
      "Epoch 82/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0305 - val_loss: 0.0425\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.03953\n",
      "Epoch 83/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0293 - val_loss: 0.0443\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.03953\n",
      "Epoch 84/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0307 - val_loss: 0.0437\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03953\n",
      "Epoch 85/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0294 - val_loss: 0.0441\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.03953\n",
      "Epoch 86/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.0303 - val_loss: 0.0417\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03953\n",
      "Epoch 87/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0284 - val_loss: 0.0435\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03953\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600/9600 [==============================] - 1s 75us/step - loss: 0.0289 - val_loss: 0.0441\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.03953\n",
      "Epoch 89/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.0279 - val_loss: 0.0420\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03953\n",
      "Epoch 90/100\n",
      "9600/9600 [==============================] - 1s 73us/step - loss: 0.0288 - val_loss: 0.0429\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.03953\n",
      "Epoch 91/100\n",
      "9600/9600 [==============================] - 1s 76us/step - loss: 0.0301 - val_loss: 0.0427\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.03953\n",
      "Epoch 92/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0290 - val_loss: 0.0428\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03953\n",
      "Epoch 93/100\n",
      "9600/9600 [==============================] - 1s 78us/step - loss: 0.0283 - val_loss: 0.0459\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03953\n",
      "Epoch 94/100\n",
      "9600/9600 [==============================] - 1s 74us/step - loss: 0.0282 - val_loss: 0.0430\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.03953\n",
      "Epoch 95/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.0287 - val_loss: 0.0442\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03953\n",
      "Epoch 96/100\n",
      "9600/9600 [==============================] - 1s 69us/step - loss: 0.0274 - val_loss: 0.0442\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03953\n",
      "Epoch 97/100\n",
      "9600/9600 [==============================] - 1s 72us/step - loss: 0.0281 - val_loss: 0.0429\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03953\n",
      "Epoch 98/100\n",
      "9600/9600 [==============================] - 1s 70us/step - loss: 0.0271 - val_loss: 0.0455\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03953\n",
      "Epoch 99/100\n",
      "9600/9600 [==============================] - 1s 76us/step - loss: 0.0278 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03953\n",
      "Epoch 100/100\n",
      "9600/9600 [==============================] - 1s 71us/step - loss: 0.0283 - val_loss: 0.0442\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.03953\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "checkpointer = ModelCheckpoint(filepath='models/weights.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.0001))\n",
    "model.fit(X_train, Y_train, \n",
    "          validation_data=(X_val, Y_val),\n",
    "          shuffle=True, epochs=100, callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "model.save('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "model.load_weights('models/weights.best.hdf5')\n",
    "model.save('models/model.best.h5')\n",
    "\n",
    "#model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3.6",
   "language": "python",
   "name": "tensorflow3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
